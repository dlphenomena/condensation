{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condensation Phenomenon \n",
    "The condensation phenomenon in neural networks describes how, during the nonlinear training of neural networks, neurons in the same layer tend to condense into groups with similar outputs. We will demonstrate this effect in the accompanying code example, using a fully connected network trained to fit a one-dimensional function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Papers\n",
    "[1] Tao Luo#, Zhi-Qin John Xu#, Zheng Ma, Yaoyu Zhang*, Phase diagram for two-layer ReLU neural networks at infinite-width limit. arxiv 2007.07497 (2020), Journal of Machine Learning Research (2021) [pdf](https://ins.sjtu.edu.cn/people/xuzhiqin/pub/phasediagram2020.pdf), and in [arxiv](https://arxiv.org/abs/2007.07497). \n",
    "\n",
    "[2] Hanxu Zhou, Qixuan Zhou, Tao Luo, Yaoyu Zhang*, Zhi-Qin John Xu*, Towards Understanding the Condensation of Neural Networks at Initial Training. arxiv 2105.11686 (2021) [pdf](https://ins.sjtu.edu.cn/people/xuzhiqin/pub/initial2105.11686.pdf), and in [arxiv](https://arxiv.org/abs/2105.11686), see slides and [video talk in Chinese](https://www.bilibili.com/video/BV1tb4y1d7CZ/?spm_id_from%253D333.999.0.0), NeurIPS2022. \n",
    "\n",
    "[3] Zhi-Qin John Xu*, Yaoyu Zhang, Zhangchen Zhou, An overview of condensation phenomenon in deep learning. arXiv:2504.09484 (2025), [pdf](https://ins.sjtu.edu.cn/people/xuzhiqin/pub/condensationoverview2025.pdf), and in [arxiv](https://arxiv.org/abs/2504.09484).\n",
    "\n",
    "For more details, see [xuzhiqin condense](https://ins.sjtu.edu.cn/people/xuzhiqin/pubcondense.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import some commonly used libraries.\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condense \n",
    "![Condense](./pic/condense.png)\n",
    "This is an ideal illustration of condensation. At initialization, the input weights of each neuron differ greatly due to randomly initialization, represented by different colors. However, after a period of training, the intermediate hidden neurons are divided into two groups: the first two neurons form one group, and the last three form another. Within each group, the input weights of different neurons are exactly the same (same color), and thus their outputs are also identical."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Default configuration parameter settings.\n",
    "`argparse` is a Python package that provides a convenient way to parse command line arguments. It allows us to define the arguments our program expects and will parse them for us. This makes it easy to write user-friendly command-line interfaces for our programs.\n",
    "\n",
    "To use `argparse`, we first create an `ArgumentParser` object, which will hold all the information necessary to parse the command-line arguments. We then define the arguments we expect using the `add_argument` method. This method takes several parameters, such as the name of the argument, its type, and a help message.\n",
    "\n",
    "In this code, we are using `argparse` to parse the command-line arguments that are passed to the program. We define several arguments, such as the learning rate, optimizer, and number of epochs, and then parse them using `args, unknown = parser.parse_known_args()`. This allows us to easily customize the behavior of our program without having to modify the code itself.\n",
    "\n",
    "Please note that you should specify the path to your own directory for saving experiment results in `ini_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch 1D dataset Training')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--lr', default=0.00001, type=float, help='learning rate')  # 学习率\n",
    "parser.add_argument('--optimizer', default='adam', help='optimizer: sgd | adam')  # 优化器选择：sgd 或 adam\n",
    "parser.add_argument('--epochs', default=2000, type=int, metavar='N', help='number of total epochs to run')  # 总训练轮数\n",
    "parser.add_argument('--test_size', default=10000, type=int, help='the test size for model (default: 10000)')  # 测试集大小\n",
    "parser.add_argument('--save', default='trained_nets', help='path to save trained nets')  # 保存训练模型的路径\n",
    "parser.add_argument('--save_epoch', default=10, type=int, help='save every save_epochs')  # 每多少轮保存一次模型\n",
    "parser.add_argument('--rand_seed', default=0, type=int, help='seed for random num generator')  # 随机数生成器的种子\n",
    "parser.add_argument('--gamma', type=float, default=2, help='parameter initialization distribution variance power(We first assume that each layer is the same width.)')  # 参数初始化分布方差幂（假设每层宽度相同）\n",
    "parser.add_argument('--boundary', nargs='+', type=str, default=['-1', '1'], help='the boundary of 1D data')  # 一维数据的边界\n",
    "parser.add_argument('--training_size', default=4, type=int, help='the training size for model (default: 1000)')  # 训练集大小\n",
    "parser.add_argument('--act_func_name', default='Tanh', help='activation function')  # 激活函数名称\n",
    "parser.add_argument('--hidden_layers_width', nargs='+', type=int, default=[1000])  # 隐藏层宽度\n",
    "parser.add_argument('--input_dim', default=1, type=int, help='the input dimension for model (default: 1)')  # 模型输入维度\n",
    "parser.add_argument('--output_dim', default=1, type=int, help='the output dimension for model (default: 1)')  # 模型输出维度\n",
    "parser.add_argument('--device', default='cuda', type=str, help='device used to train (cpu or cuda)')  # 训练使用的设备（CPU 或 CUDA）\n",
    "parser.add_argument('--plot_epoch', default=100, type=int, help='step size of plotting interval (default: 1000)')  # 绘图间隔的步长\n",
    "parser.add_argument('--ini_path', default='***', type=str, help='the path to save experiment results')  # 保存实验结果的路径\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Make the Directories of the Expetiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdirs(fn):  # Create directories\n",
    "    if not os.path.isdir(fn):\n",
    "        os.makedirs(fn)\n",
    "    return fn\n",
    "\n",
    "\n",
    "def create_save_dir(path_ini): \n",
    "    subFolderName = re.sub(r'[^0-9]', '', str(datetime.datetime.now()))\n",
    "    path = os.path.join(path_ini, subFolderName)\n",
    "    mkdirs(path)\n",
    "    # mkdirs(os.path.join(path, 'output'))\n",
    "    return path\n",
    "\n",
    "\n",
    "args.path = create_save_dir(args.ini_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data for training and testing\n",
    "The target function is:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x)=0.2*\\mathrm{ReLU}(x-1/3) + 0.2*\\mathrm{ReLU} (-x-1/3)\n",
    "\\end{equation}\n",
    "where the data boundaries are $[-1,1]$.\n",
    "\n",
    "If you need to modify the target function, you can change in the `get_y` function. After running this code block, you will obtain an image of the target function, where the blue points represent the training data and the red line represents the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(x):  # Function to fit\n",
    "    y = 0.2*torch.relu(-1/3+x) + 0.2*torch.relu(-1/3-x)\n",
    "    return y\n",
    "\n",
    "for i in range(2):\n",
    "    if isinstance(args.boundary[i], str):\n",
    "        args.boundary[i] = eval(args.boundary[i])\n",
    "\n",
    "args.test_input = torch.reshape(torch.linspace(args.boundary[0], args.boundary[1], steps=args.test_size), [args.test_size, 1])\n",
    "\n",
    "\n",
    "args.training_input = torch.reshape(torch.linspace(args.boundary[0], args.boundary[1], steps=args.training_size), [args.training_size, 1])\n",
    "args.test_target = get_y(args.test_input)\n",
    "args.training_target = get_y(args.training_input)\n",
    "\n",
    "\n",
    "def plot_target(args):\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    plt.plot(args.training_input.detach().cpu().numpy(),\n",
    "             args.training_target.detach().cpu().numpy(), 'b*', label='True')\n",
    "    plt.plot(args.test_input.detach().cpu().numpy(),\n",
    "             args.test_target.detach().cpu().numpy(), 'r-', label='Test')\n",
    "\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_target(args)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network model and parameter initialization.\n",
    "\n",
    "Given $\\theta\\in \\mathbb{R}^M$, the FNN function $f_{\\theta}(\\cdot)$ is defined recursively. First, we denote $f^{[0]}_{\\theta}(x)=x$ for all $x\\in\\mathbb{R}^d$. Then, for $l\\in[L-1]$, $f^{[l]}_{\\theta}$ is defined recursively as \n",
    "$f^{[l]}_{\\theta}(x)=\\sigma (W^{[l]} f^{[l-1]}_{\\theta}(x)+b^{[l]})$, where $\\sigma$ is a non-linear activation function.\n",
    "Finally, we denote\n",
    "\\begin{equation*}\n",
    "    f_{\\theta}(x)=f(x,\\theta)=f^{[L]}_{\\theta}(x)=W^{[L]} f^{[L-1]}_{\\theta}(x)+b^{[L]}.\n",
    "\\end{equation*}\n",
    "\n",
    "The parameter initialization is under the Gaussian distribution as follows,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\theta_{l} \\sim N(0, \\frac{1}{m_{l}^{\\gamma}}),\n",
    "\\end{equation*}\n",
    "where the $l$ th layer parameters of $\\theta$ is the ordered pair $\\theta_{l}=\\Big(W^{[l]},b^{[l]}\\Big),\\quad l\\in[L]$, $m_{l}$ is the width of the $l$ th layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, gamma, hidden_layers_width=[100],  input_size=20, num_classes: int = 1000, act_layer: nn.Module = nn.ReLU()):\n",
    "        super(Linear, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers_width = hidden_layers_width\n",
    "        self.gamma = gamma\n",
    "        layers: List[nn.Module] = []\n",
    "        self.layers_width = [self.input_size]+self.hidden_layers_width\n",
    "        for i in range(len(self.layers_width)-1):\n",
    "            layers += [nn.Linear(self.layers_width[i],\n",
    "                                    self.layers_width[i+1]), act_layer]\n",
    "        layers += [nn.Linear(self.layers_width[-1], num_classes, bias=False)]\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self) -> None:\n",
    "\n",
    "        for obj in self.modules():\n",
    "            if isinstance(obj, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.normal_(obj.weight.data, 0, 1 /\n",
    "                                self.hidden_layers_width[0]**(self.gamma))\n",
    "                if obj.bias is not None:\n",
    "                    nn.init.normal_(obj.bias.data, 0, 1 /\n",
    "                                    self.hidden_layers_width[0]**(self.gamma))\n",
    "\n",
    "\n",
    "def get_act_func(act_func):\n",
    "    if act_func == 'Tanh':\n",
    "        return nn.Tanh()\n",
    "    elif act_func == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif act_func == 'Sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    else:\n",
    "        raise NameError('No such act func!')\n",
    "\n",
    "\n",
    "act_func = get_act_func(args.act_func_name)\n",
    "\n",
    "model = Linear(args.gamma, args.hidden_layers_width, args.input_dim,\n",
    "               args.output_dim, act_func).to(args.device)\n",
    "\n",
    "para_init = copy.deepcopy(model.state_dict())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-step training function.\n",
    "\n",
    "The training data set is denoted as  $S=\\{(x_i,y_i)\\}_{i=1}^n$, where $x_i\\in\\mathbb{R}^d$ and $y_i\\in \\mathbb{R}^{d'}$. For simplicity, we assume an unknown function $y$ satisfying $y(x_i)=y_i$ for $i\\in[n]$. The empirical risk reads as\n",
    "\\begin{equation*}\n",
    "    R_S(\\theta)=\\frac{1}{n}\\sum_{i=1}^n\\ell(f(x_i,\\theta),y(x_i)),\n",
    "\\end{equation*}\n",
    "where the loss function $\\ell(\\cdot,\\cdot)$ is differentiable and the derivative of $\\ell$ with respect to its first argument is denoted by $\\nabla\\ell(y,y^*)$. \n",
    "\n",
    "For a one-step gradient descent, we have, \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\theta_{t+1}=\\theta_t-\\eta\\nabla R_S(\\theta).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(model, optimizer, loss_fn,  args):\n",
    "\n",
    "    model.train()\n",
    "    device = args.device\n",
    "    data, target = args.training_input.to(\n",
    "        device), args.training_target.to(device).to(torch.float)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(data)\n",
    "    loss = loss_fn(outputs, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-step test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_fn, args):\n",
    "    model.eval()\n",
    "    device = args.device\n",
    "    with torch.no_grad():\n",
    "        data, target = args.test_input.to(\n",
    "            device), args.test_target.to(device).to(torch.float)\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, target)\n",
    "\n",
    "    return loss.item(), outputs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss value during the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(path, loss_train, x_log=False):\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    y2 = np.asarray(loss_train)\n",
    "    plt.plot(y2, 'k-', label='Train')\n",
    "    plt.xlabel('epoch', fontsize=18)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.yscale('log')\n",
    "    if x_log == False:\n",
    "        fntmp = os.path.join(path, 'loss.jpg')\n",
    "\n",
    "    else:\n",
    "        plt.xscale('log')\n",
    "        fntmp = os.path.join(path, 'loss_log.jpg')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fntmp,dpi=300)\n",
    "\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the figure of the model output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_output(path, args, output, epoch):\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    plt.plot(args.training_input.detach().cpu().numpy(),\n",
    "             args.training_target.detach().cpu().numpy(), 'b*', label='True')\n",
    "    plt.plot(args.test_input.detach().cpu().numpy(),\n",
    "             output.detach().cpu().numpy(), 'r-', label='Test')\n",
    "\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    fn = mkdirs(os.path.join('%s'%path,'output'))\n",
    "    fntmp = os.path.join(fn, str(epoch)+'.jpg')\n",
    "\n",
    "    plt.savefig(fntmp, dpi=300)\n",
    "\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Orientation and Amplitude of Neurons in the Hidden Layer of a Two-Layer Network\n",
    "\n",
    "The mathematical expression of a two-layer fully connected network is as follows:\n",
    "\n",
    "$$\n",
    "f_{\\boldsymbol{\\theta}}(\\boldsymbol{x})= \\sum_{k=1}^m a_k \\sigma\\left(\\boldsymbol{w}_k^{\\top} \\boldsymbol{x}\\right)\n",
    "$$\n",
    "\n",
    "In this formula, $\\boldsymbol{w}_k = (w_k,b_k)^T$ is the weight and bias of the $k$-th neuron, $\\boldsymbol{x} =(x,1)^T$ is the input vector (note that we incorporate the bias term into the weight vector).\n",
    "\n",
    "Now, let us introduce two important concepts:\n",
    "\n",
    "1. Neuron's orientation: defined as $\\frac{w_k}{|\\boldsymbol{w}_k|_2}$. This represents the direction of the neuron in the input space.\n",
    "\n",
    "2. Neuron's amplitude: defined as $|a_k|\\cdot|\\boldsymbol{w_k}|_2$. This reflects the degree of influence of the neuron on the output.\n",
    "\n",
    "We define $\\left(\\frac{w_k}{|\\boldsymbol{w}_k|_2}, |a_k|\\cdot|\\boldsymbol{w_k}|_2\\right)$ as the feature of the neuron.\n",
    "\n",
    "Next, let's look at the parameter initialization method for this network:\n",
    "\n",
    "$a_k^0\\sim \\mathcal{N}(0,\\beta_1^2),\\quad \\boldsymbol{w_k^0}\\sim\\mathcal{N}(0,\\beta_2^2\\boldsymbol{I}_d)$\n",
    "\n",
    "Here, $a_k^0$ and $\\boldsymbol{w_k^0}$ are the initial values of $a_k$ and $\\boldsymbol{w_k}$, respectively. They are randomly sampled from Gaussian distributions. Generally, the magnitudes of $\\beta_1, \\beta_2$ are powers of $m$, i.e., $m^{-t}$.\n",
    "\n",
    "Now, we introduce two important parameters $\\gamma$ and $\\gamma'$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\gamma = \\lim_{m\\rightarrow \\infty}-\\frac{\\log\\beta_1\\beta_2/\\alpha}{\\log m}, \\quad \\gamma'=\\lim_{m\\rightarrow \\infty} -\\frac{\\log\\beta_1/\\beta_2}{\\log m}\n",
    "\\end{equation*}\n",
    "\n",
    "These two parameters describe how the variances of the initialization distributions ($\\beta_1$ and $\\beta_2$) change as the network width $m$ increases. They have a significant impact on the training dynamics of the network.\n",
    "\n",
    "In particular, when we use the ReLU activation function, i.e., $\\sigma(x)=\\mathrm{ReLU}(x)$, we can obtain a phase diagram. This phase diagram shows how different values of $\\gamma$ and $\\gamma'$ affect the behavior of the network.\n",
    "\n",
    "![phase](./pic/phase.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions to Visualize Neuron Features During Training\n",
    "\n",
    "1. The `get_ori_A` function computes the features of each neuron in a specific checkpoint.\n",
    "\n",
    "2. The `get_ori_A_list` function integrates the neuron features from different checkpoints into a list.\n",
    "\n",
    "3. The `plot_feature` function visualizes the neuron features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter(checkpoint):\n",
    "    wei1 = checkpoint['features.0.weight']\n",
    "    bias = checkpoint['features.0.bias']\n",
    "    wei2 = checkpoint['features.2.weight']\n",
    "\n",
    "    return wei1, bias, wei2\n",
    "\n",
    "# To get the orientation and amplitude of each neuron in different layer.\n",
    "def get_ori_A(checkpoint):\n",
    "    wei1, bias, wei2 = get_parameter(checkpoint)\n",
    "\n",
    "    wei1 = wei1.squeeze()\n",
    "    bias = bias.squeeze()\n",
    "    wei2 = wei2.squeeze()\n",
    "    wei = wei1 / (wei1 ** 2 + bias ** 2)**(1/2)\n",
    "\n",
    "    bia = bias / (wei1 ** 2 + bias ** 2)**(1/2)\n",
    "    ori = torch.sign(bia) * torch.acos(wei)\n",
    "    A = wei2 * (wei1 ** 2 + bias ** 2)**(1/2)\n",
    "\n",
    "    return ori, A\n",
    "\n",
    "# get the orientation and amplitude of each neuron at the beginning and end of training.\n",
    "def get_ori_A_list(checkpoint_list):\n",
    "\n",
    "    if not isinstance(checkpoint_list, list):\n",
    "        ori, A=get_ori_A(checkpoint_list)\n",
    "        return [ori], [A]\n",
    "\n",
    "    else:\n",
    "        ori_ini, A_ini = get_ori_A(checkpoint_list[0])\n",
    "\n",
    "        ori, A = get_ori_A(checkpoint_list[1])\n",
    "\n",
    "        return [ori_ini, ori], [A_ini, A]\n",
    "    \n",
    "def plot_feature(path, ori, A, args, nota=''):\n",
    "    \"\"\"\n",
    "    It plots the feature of the input data\n",
    "    \n",
    "    :param path: the path to save the figure\n",
    "    :param ori: the feature orientation\n",
    "    :param A: the feature amplitude\n",
    "    :param args: the parameters of the model\n",
    "    \"\"\"\n",
    "\n",
    "    if args.input_dim == 1:\n",
    "\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "\n",
    "        if len(ori) == 1:\n",
    "\n",
    "            ori = ori[0].squeeze().detach().cpu().numpy()\n",
    "            A = A[0].squeeze().detach().cpu().numpy()\n",
    "\n",
    "        elif len(ori) == 2:\n",
    "            ori_ini, ori = ori[0].squeeze().detach().cpu(\n",
    "            ).numpy(), ori[1].squeeze().detach().cpu().numpy()\n",
    "            A_ini, A = A[0].squeeze().detach().cpu().numpy(\n",
    "            ), A[1].squeeze().detach().cpu().numpy()\n",
    "\n",
    "            print(ori_ini.shape, A_ini.shape)\n",
    "\n",
    "            plt.scatter(ori_ini, abs(A_ini), color='cyan', label='ini feature')\n",
    "\n",
    "        else:\n",
    "            raise Exception('The length of the checkpoint list is less than or equal to two.')\n",
    "\n",
    "        # mkdirs(r'%s\\\\feature' % (path))\n",
    "        fn = mkdirs(os.path.join('%s'%path,'feature'))\n",
    "        plt.scatter(ori, abs(A), color='r', label='fin feature')\n",
    "        plt.xlim(-3.16,3.16)\n",
    "        plt.xlabel('orientation', fontsize=18)\n",
    "        plt.ylabel('amplitude', fontsize=18)\n",
    "        plt.legend(fontsize=18)\n",
    "        # fntmp = r'%s\\\\feature\\\\%s' % (path, nota)\n",
    "        # fntmp = os.path.join(fn,'%s'%nota)\n",
    "        # save_fig(plt, fntmp, pdf=False, x_log=False, y_log=True)\n",
    "        plt.savefig(os.path.join(fn,'%s'%nota))\n",
    "        plt.close()\n",
    "    else:\n",
    "        raise Exception('Input dimension must equal to 1!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![out05](./999.jpg)![out1](./3999.jpg)![out2](./1999.jpg) -->\n",
    "<center class=\"half\">\n",
    "    <img src=\"./pic/999.jpg\" width=\"300\"/><img src=\"./pic/3999.jpg\" width=\"300\"/><img src=\"./pic/1999.jpg\" width=\"300\"/>\n",
    "</center>\n",
    "\n",
    "<center class=\"half\">\n",
    "    <img src=\"./pic/999.png\" width=\"300\"/><img src=\"./pic/3999.png\" width=\"300\"/><img src=\"./pic/1999.png\" width=\"300\"/>\n",
    "</center>\n",
    "\n",
    "The above figures show the expected results of neural network parameters under three different initialization scales.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Process\n",
    "With the definitions of functions related to the training process, we can now train the neural network and visualize the features of the neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args.gamma = 1\n",
    "args.lr = 0.05\n",
    "args.epochs = 10000\n",
    "args.save_epoch = 1000\n",
    "args.plot_epoch = 1000\n",
    "args.optimizer = 'sgd'\n",
    "args.act_func_name = 'ReLU'\n",
    "args.savepath = os.path.join(args.path, 't=%s'%args.gamma)\n",
    "os.makedirs(args.savepath, exist_ok=True)\n",
    "act_func = get_act_func(args.act_func_name)\n",
    "\n",
    "model = Linear(args.gamma, args.hidden_layers_width, args.input_dim,\n",
    "               args.output_dim, act_func).to(args.device)\n",
    "\n",
    "para_init = copy.deepcopy(model.state_dict())\n",
    "if args.optimizer=='sgd':\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "else:\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "t0 = time.time()\n",
    "loss_training_lst=[]\n",
    "loss_test_lst = []\n",
    "for epoch in range(args.epochs+1):\n",
    "\n",
    "      model.train()\n",
    "      loss = train_one_step(\n",
    "        model, optimizer, loss_fn, args)\n",
    "      loss_test, output = test(\n",
    "          model, loss_fn, args)\n",
    "      loss_training_lst.append(loss)\n",
    "      loss_test_lst.append(loss_test)\n",
    "      if epoch % args.plot_epoch == 0:\n",
    "            print(\"[%d] loss: %.6f valloss: %.6f time: %.2f s\" %\n",
    "                  (epoch + 1, loss, loss_test, (time.time()-t0)))\n",
    "  \n",
    "      if (epoch+1) % (args.plot_epoch) == 0:\n",
    "          plot_loss(path=args.savepath,\n",
    "                    loss_train=loss_training_lst, x_log=True)\n",
    "          plot_loss(path=args.savepath,\n",
    "                    loss_train=loss_training_lst, x_log=False)\n",
    "\n",
    "          \n",
    "          para_now = copy.deepcopy(model.state_dict())\n",
    "          ori, A = get_ori_A_list([para_init,para_now])\n",
    "          plot_feature(args.savepath, ori, A, args,nota='%s'%epoch)\n",
    "          plot_model_output(args.savepath, args, output, epoch)\n",
    "          \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
